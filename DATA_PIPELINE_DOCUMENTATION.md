# ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„¸ ë¬¸ì„œ

> **ì‘ì„±ì¼**: 2025ë…„ 10ì›” 14ì¼  
> **í”„ë¡œì íŠ¸**: ë„ì„œ-ìŠ¤í¬ë¦½íŠ¸ ë³€í™˜ LLM ëª¨ë¸ ê°œë°œ  
> **ëª©ì **: GitHub ì´ìŠˆ ë° ê¸°ìˆ  ë¬¸ì„œìš©

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•](#2-ë°ì´í„°-ìˆ˜ì§‘-ë°©ë²•)
3. [ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸](#3-ì „ì²˜ë¦¬-íŒŒì´í”„ë¼ì¸)
4. [êµ¬í˜„ ì„¸ë¶€ì‚¬í•­](#4-êµ¬í˜„-ì„¸ë¶€ì‚¬í•­)
5. [í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±](#5-í•™ìŠµ-ë°ì´í„°ì…‹-ìƒì„±)
6. [í’ˆì§ˆ ê²€ì¦](#6-í’ˆì§ˆ-ê²€ì¦)
7. [ì‹¤í–‰ ë°©ë²•](#7-ì‹¤í–‰-ë°©ë²•)
8. [ë¬¸ì œ í•´ê²°](#8-ë¬¸ì œ-í•´ê²°)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ëª©í‘œ
ë„ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” LLM ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„°ì…‹ êµ¬ì¶•

### 1.2 ë°ì´í„° ì†ŒìŠ¤
- **ì¶œì²˜**: Project Gutenberg (https://www.gutenberg.org/)
- **ë¼ì´ì„ ìŠ¤**: í¼ë¸”ë¦­ ë„ë©”ì¸
- **ë„ì„œ ìˆ˜**: 10ê¶Œ (í™•ì¥ ê°€ëŠ¥)
- **ì¥ë¥´**: ê³ ì „ ì˜ë¬¸ ì†Œì„¤

### 1.3 ì„ ì • ë„ì„œ ëª©ë¡

| Book ID | ì œëª© | ì €ì | ì˜ˆìƒ ì±•í„° ìˆ˜ |
|---------|------|------|--------------|
| 1342 | Pride and Prejudice | Jane Austen | 61 |
| 2701 | Moby Dick | Herman Melville | 135 |
| 84 | Frankenstein | Mary Shelley | 24 |
| 1661 | The Adventures of Sherlock Holmes | Arthur Conan Doyle | 12 |
| 11 | Alice's Adventures in Wonderland | Lewis Carroll | 12 |
| 98 | A Tale of Two Cities | Charles Dickens | 45 |
| 74 | The Adventures of Tom Sawyer | Mark Twain | 35 |
| 345 | Dracula | Bram Stoker | 27 |
| 46 | A Christmas Carol | Charles Dickens | 5 |
| 1952 | The Yellow Wallpaper | Charlotte Perkins Gilman | 1 |

**ì´ ì˜ˆìƒ ìƒ˜í”Œ ìˆ˜**: ì•½ 357ê°œ ì±•í„° (ì‹¤ì œ ì²˜ë¦¬ ê²°ê³¼ì— ë”°ë¼ ë³€ë™)

---

## 2. ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•

### 2.1 GutenbergCollector í´ë˜ìŠ¤

#### ì£¼ìš” ê¸°ëŠ¥
```python
class GutenbergCollector:
    def __init__(self):
        self.base_url = "https://www.gutenberg.org/files/"
        self.cache_dir = "./gutenberg_cache"
    
    def download_book(self, book_id):
        # ìºì‹œ í™•ì¸ â†’ ë‹¤ìš´ë¡œë“œ â†’ ì €ì¥
        pass
```

#### ë‹¤ìš´ë¡œë“œ ë¡œì§

1. **ìºì‹œ í™•ì¸**
   - ë¨¼ì € `./gutenberg_cache/book_{id}.txt` íŒŒì¼ ì¡´ì¬ í™•ì¸
   - ìºì‹œê°€ ìˆìœ¼ë©´ íŒŒì¼ì—ì„œ ì½ê¸° (ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì ˆì•½)

2. **ë„¤íŠ¸ì›Œí¬ ë‹¤ìš´ë¡œë“œ**
   - URL íŒ¨í„´ 1: `https://www.gutenberg.org/files/{id}/{id}-0.txt`
   - URL íŒ¨í„´ 2 (ì‹¤íŒ¨ ì‹œ): `https://www.gutenberg.org/files/{id}/{id}.txt`
   - `requests.get()` with 30ì´ˆ íƒ€ì„ì•„ì›ƒ

3. **ì €ì¥**
   - UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ìºì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥
   - ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì¬ì‚¬ìš©

#### ì—ëŸ¬ ì²˜ë¦¬
```python
try:
    # ë©”ì¸ URL ì‹œë„
    response = requests.get(url, timeout=30)
    response.raise_for_status()
except Exception as e:
    # ëŒ€ì²´ URL ì‹œë„
    alt_response = requests.get(alt_url, timeout=30)
```

### 2.2 ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼

**ì˜ˆìƒ ê²°ê³¼ë¬¼**:
```
gutenberg_cache/
â”œâ”€â”€ book_1342.txt  (717 KB)
â”œâ”€â”€ book_2701.txt  (1.2 MB)
â”œâ”€â”€ book_84.txt    (448 KB)
â”œâ”€â”€ book_1661.txt  (594 KB)
â”œâ”€â”€ book_11.txt    (170 KB)
â”œâ”€â”€ book_98.txt    (788 KB)
â”œâ”€â”€ book_74.txt    (408 KB)
â”œâ”€â”€ book_345.txt   (881 KB)
â”œâ”€â”€ book_46.txt    (176 KB)
â””â”€â”€ book_1952.txt  (63 KB)

Total: ~5.4 MB
```

---

## 3. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### 3.1 íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜

```
ì›ë³¸ í…ìŠ¤íŠ¸ (Raw Text)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Gutenberg í—¤ë”/í‘¸í„° ì œê±°         â”‚
â”‚     - START/END ë§ˆì»¤ ê°ì§€            â”‚
â”‚     - ì €ì‘ê¶Œ ì •ë³´ ì œê±°               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ì œ                 â”‚
â”‚     - ê³¼ë„í•œ ê³µë°± ì œê±°               â”‚
â”‚     - ì¤„ë°”ê¿ˆ ì •ê·œí™”                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. ëª©ì°¨(TOC) ì œê±°                   â”‚
â”‚     - "CONTENTS" ì„¹ì…˜ ê°ì§€           â”‚
â”‚     - ì‹¤ì œ ì±•í„°ì™€ êµ¬ë¶„               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. ì±•í„° ë¶„í•                         â”‚
â”‚     - ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ë§¤ì¹­           â”‚
â”‚     - ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„ ë° ê²€ì¦         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ê°œì²´ëª… ì¶”ì¶œ (NER)                â”‚
â”‚     - SpaCy en_core_web_sm           â”‚
â”‚     - PERSON, GPE, LOC, DATE ë“±      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡°í™”                  â”‚
â”‚     - ëŒ€í™”ë¬¸ ì¶”ì¶œ                    â”‚
â”‚     - ì„œìˆ  ë¬¸ì¥ ë¶„ë¦¬                 â”‚
â”‚     - ì”¬ ì •ë³´ êµ¬ì„±                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
í•™ìŠµ ë°ì´í„°ì…‹ (Training Dataset)
```

### 3.2 TextPreprocessor í´ë˜ìŠ¤

#### 3.2.1 í—¤ë”/í‘¸í„° ì œê±°

**ëª©ì **: Project Gutenbergì˜ ë©”íƒ€ë°ì´í„° ì œê±°

**êµ¬í˜„**:
```python
def remove_gutenberg_header_footer(self, text):
    start_markers = [
        "*** START OF THIS PROJECT GUTENBERG",
        "*** START OF THE PROJECT GUTENBERG",
        "***START OF THE PROJECT GUTENBERG"
    ]
    end_markers = [
        "*** END OF THIS PROJECT GUTENBERG",
        "*** END OF THE PROJECT GUTENBERG",
        "***END OF THE PROJECT GUTENBERG"
    ]
    # ë§ˆì»¤ ì‚¬ì´ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
```

**íš¨ê³¼**:
- í‰ê·  ~5-10% í…ìŠ¤íŠ¸ ì œê±°
- ë¼ì´ì„ ìŠ¤ ì •ë³´, ê¸°ë¶€ ì•ˆë‚´ ë“± ì œê±°

#### 3.2.2 ëª©ì°¨ ì œê±° (ê°œì„  ë²„ì „ v4)

**ëª©ì **: ì‹¤ì œ ì±•í„° ë‚´ìš©ë§Œ ë³´ì¡´, ëª©ì°¨ í•­ëª© ì œê±°

**ì•Œê³ ë¦¬ì¦˜**:
```python
def remove_table_of_contents(self, text):
    # 1. ëª©ì°¨ ì‹œì‘ ê°ì§€
    #    - "CONTENTS", "TABLE OF CONTENTS" ë‹¨ë… ë¼ì¸
    #    - "Heading to Chapter" íŒ¨í„´ ì—°ì† 2ì¤„ ì´ìƒ
    
    # 2. ì‹¤ì œ ì±•í„° í™•ì¸
    #    - "CHAPTER X" íŒ¨í„´ ë§¤ì¹­
    #    - ë‹¤ìŒ 10ì¤„ ë‚´ 40ì ì´ìƒ ë¬¸ì¥ í™•ì¸
    #    - ëª©ì°¨ í‚¤ì›Œë“œ ì—†ìŒ í™•ì¸
    
    # 3. ëª©ì°¨ ì¢…ë£Œ
    #    - ì²« ì‹¤ì œ ì±•í„° ë°œê²¬ ì‹œ
    #    - ë˜ëŠ” 150ì¤„ ì´ˆê³¼ ì‹œ
```

**ê°œì„  ì‚¬í•­**:
- âœ… Pride and Prejudiceì˜ "Heading to Chapter" íŒ¨í„´ ì²˜ë¦¬
- âœ… ì‹¤ì œ ì±•í„°ì™€ ëª©ì°¨ í•­ëª© êµ¬ë¶„ ê°•í™”
- âœ… False positive ê°ì†Œ (ëª©ì°¨ê°€ ì•„ë‹Œë° ì œê±°ë˜ëŠ” ê²½ìš°)

#### 3.2.3 ì±•í„° ë¶„í•  (ê°œì„  ë²„ì „ v2)

**ì§€ì› íŒ¨í„´**:
1. `CHAPTER I`, `Chapter 1`, `CHAPTER ONE`
2. `BOOK I`, `PART I`
3. ì±•í„° ì œëª© í¬í•¨: `CHAPTER I. The Beginning`

**ì•Œê³ ë¦¬ì¦˜**:
```python
def split_into_chapters(self, text):
    # 1ë‹¨ê³„: ëª©ì°¨ ì œê±°
    text_without_toc = self.remove_table_of_contents(text)
    
    # 2ë‹¨ê³„: ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„
    patterns = [
        r'\n\s*(CHAPTER|Chapter)\s+([IVXLCDM]+|\d+|One|Two|...)',
        r'\n\s*(BOOK|Book|PART|Part)\s+([IVXLCDM]+|\d+)',
    ]
    
    # 3ë‹¨ê³„: ìµœì  íŒ¨í„´ ì„ íƒ
    #   - 2-150ê°œ ì±•í„°
    #   - í‰ê·  ê¸¸ì´ 300ì ì´ìƒ
    #   - ìµœëŒ€ ì±•í„° ìˆ˜ ìš°ì„ 
    
    # 4ë‹¨ê³„: ì±•í„° ì¶”ì¶œ ë° ê²€ì¦
    #   - ë‚´ìš© ê¸¸ì´ 200ì ì´ìƒ
    #   - ì œëª© ì¶”ì¶œ (ì²« ì¤„ 60ì ì´í•˜)
```

**íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬**:
- ê° íŒ¨í„´ë‹¹ 3ì´ˆ ì œí•œ
- Catastrophic backtracking ë°©ì§€

**Fallback ë©”ì»¤ë‹ˆì¦˜**:
- ì •ê·œì‹ ì‹¤íŒ¨ ì‹œ ì¤„ ë‹¨ìœ„ ë¶„ì„
- ìˆ˜ë™ ì±•í„° ë§ˆì»¤ íƒì§€

**ê²€ì¦ ê¸°ì¤€**:
- âœ… ìµœì†Œ 2ê°œ ì´ìƒì˜ ì±•í„°
- âœ… í‰ê·  ì±•í„° ê¸¸ì´ 300ì ì´ìƒ
- âœ… ì‹¤ì œ ë‚´ìš© í¬í•¨ í™•ì¸

### 3.3 EntityExtractor í´ë˜ìŠ¤

#### 3.3.1 SpaCy NER íŒŒì´í”„ë¼ì¸

**ëª¨ë¸**: `en_core_web_sm`
- í¬ê¸°: 13 MB
- ì •í™•ë„: ~85% (ì¼ë°˜ í…ìŠ¤íŠ¸)
- ì²˜ë¦¬ ì†ë„: ~1,000 ë‹¨ì–´/ì´ˆ

**ì¶”ì¶œ ê°œì²´ ìœ í˜•**:
```python
entities = {
    'PERSON': [],   # ì¸ë¬¼ (Elizabeth, Darcy)
    'GPE': [],      # ì§€ì •í•™ì  ê°œì²´ (London, England)
    'LOC': [],      # ìœ„ì¹˜ (Netherfield Park)
    'DATE': [],     # ë‚ ì§œ (November, 1813)
    'TIME': [],     # ì‹œê°„ (morning, evening)
    'ORG': [],      # ì¡°ì§ (None in novels)
    'EVENT': []     # ì´ë²¤íŠ¸ (Ball, Wedding)
}
```

#### 3.3.2 ë¹ˆë„ìˆ˜ ê³„ì‚°

**ë°©ë²•**:
```python
# ì¤‘ë³µ ì œê±° ë° ë¹ˆë„ìˆ˜ ì§‘ê³„
entity_counts = defaultdict(int)
for entity in entities[category]:
    entity_counts[entity] += 1

# ë¹ˆë„ìˆœ ì •ë ¬
sorted_entities = sorted(
    entity_counts.items(), 
    key=lambda x: x[1], 
    reverse=True
)
```

**ì˜ˆì‹œ ì¶œë ¥** (Pride and Prejudice, Chapter 1):
```
PERSON: [('Elizabeth', 15), ('Darcy', 12), ('Mr. Bennet', 8), ...]
GPE: [('Netherfield', 5), ('Meryton', 3), ('London', 2)]
LOC: [('Longbourn', 4), ('Park', 2)]
```

### 3.4 ScriptFormatter í´ë˜ìŠ¤

#### 3.4.1 ëŒ€í™”ë¬¸ ì¶”ì¶œ

**íŒ¨í„´**:
```python
dialogue_pattern = r'["\']([^"\']+)["\']'
dialogues = re.findall(dialogue_pattern, text)
```

**í•„í„°ë§**:
- ìµœì†Œ 3ë‹¨ì–´ ì´ìƒ
- íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸

**ì˜ˆì‹œ**:
```python
# ì…ë ¥
"How do you do?" said Mr. Darcy.
"I am well, thank you," replied Elizabeth.

# ì¶œë ¥
['How do you do?', 'I am well, thank you']
```

#### 3.4.2 ì„œìˆ  ì¶”ì¶œ

**ë°©ë²•**:
```python
# ëŒ€í™”ë¬¸ ì œê±°
narrative = re.sub(r'["\'][^"\']+["\']', '', text)
# ì •ì œ
narrative = re.sub(r' +', ' ', narrative)
```

**ì˜ˆì‹œ**:
```python
# ì…ë ¥
She walked into the room. "Hello," she said.

# ì¶œë ¥ (ì„œìˆ ë§Œ)
She walked into the room.  she said.
```

#### 3.4.3 ì”¬ êµ¬ì¡° ìƒì„±

**êµ¬ì„± ìš”ì†Œ**:
```python
scene_data = {
    'characters': top_5_characters,
    'locations': top_3_locations,
    'dialogues': first_10_dialogues,
    'narrative_sentences': first_20_sentences,
    'total_sentences': count,
    'total_dialogues': count
}
```

---

## 4. êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 4.1 BookToScriptPipeline í´ë˜ìŠ¤

**ì „ì²´ ì›Œí¬í”Œë¡œìš°**:

```python
class BookToScriptPipeline:
    def process_book(self, book_id):
        # 1. ë‹¤ìš´ë¡œë“œ
        book_text = self.collector.download_book(book_id)
        
        # 2. ì „ì²˜ë¦¬
        cleaned_text = self.preprocessor.remove_gutenberg_header_footer(book_text)
        cleaned_text = self.preprocessor.clean_text(cleaned_text)
        
        # 3. ì±•í„° ë¶„í• 
        chapters = self.preprocessor.split_into_chapters(cleaned_text)
        
        # 4. ê° ì±•í„° ì²˜ë¦¬ (ì²˜ìŒ 5ê°œë§Œ)
        for chapter in chapters[:5]:
            # ê°œì²´ëª… ì¶”ì¶œ
            entities = self.extractor.extract_entities(chapter['content'])
            
            # ì”¬ êµ¬ì¡° ìƒì„±
            scene_data = self.formatter.create_scene_structure(
                chapter['content'], 
                entities
            )
        
        return processed_data
```

**ì²˜ë¦¬ ì œí•œ**:
- ì±•í„°ë‹¹ ì²˜ìŒ 5ê°œë§Œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ë° ì‹œê°„ ì ˆì•½)
- ì „ì²´ ì²˜ë¦¬ëŠ” `process_multiple_books()` ì‚¬ìš©

### 4.2 ë©”ëª¨ë¦¬ ìµœì í™”

**SpaCy max_length ì„¤ì •**:
```python
self.nlp.max_length = 1000000  # 1MB
text_to_process = text[:1000000]  # ì´ˆê³¼ ì‹œ ì˜ë¼ë‚´ê¸°
```

**ì´ìœ **:
- SpaCy ê¸°ë³¸ ì œí•œ: 1,000,000 ë¬¸ì
- Moby Dick ê°™ì€ ê¸´ ì±… ì²˜ë¦¬ ê°€ëŠ¥

---

## 5. í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±

### 5.1 DatasetBuilder í´ë˜ìŠ¤

#### 5.1.1 í•™ìŠµ ìƒ˜í”Œ ìƒì„±

**ì…ë ¥ í¬ë§·**:
```python
input_text = f"""Convert the following book chapter into a video script format. 
Extract key elements including characters, locations, dialogues, and narrative descriptions.

Chapter: {chapter_title}

Text:
{chapter_text[:2000]}"""  # ì²˜ìŒ 2000ì
```

**ì¶œë ¥ í¬ë§·** (JSON):
```json
{
  "scene_title": "CHAPTER I",
  "characters": ["Elizabeth", "Darcy", "Mr. Bennet"],
  "locations": ["Longbourn", "Netherfield"],
  "dialogues": [
    "How do you do?",
    "I am well, thank you"
  ],
  "narrative": "She walked into the room. He stood by the window.",
  "total_sentences": 45,
  "total_dialogues": 12
}
```

**í† í° ì œí•œ ê³ ë ¤**:
- ì…ë ¥: ì²˜ìŒ 2000ì (ì•½ 400 í† í°)
- LLM í† í° ì œí•œ ëŒ€ì‘ (GPT-2: 1024, T5: 512)

#### 5.1.2 ë°ì´í„°ì…‹ ë¶„í• 

**ë¹„ìœ¨**:
- Train: 80%
- Validation: 10%
- Test: 10%

**ì½”ë“œ**:
```python
from sklearn.model_selection import train_test_split

# ì²« ë²ˆì§¸ ë¶„í• 
train_data, temp_data = train_test_split(
    samples, test_size=0.2, random_state=42
)

# ë‘ ë²ˆì§¸ ë¶„í• 
val_data, test_data = train_test_split(
    temp_data, test_size=0.5, random_state=42
)
```

**ëœë¤ ì‹œë“œ**: 42 (ì¬í˜„ì„±)

#### 5.1.3 ì €ì¥

**íŒŒì¼ í˜•ì‹**: JSON
**ì¸ì½”ë”©**: UTF-8
**ë“¤ì—¬ì“°ê¸°**: 2ì¹¸ (ê°€ë…ì„±)

**íŒŒì¼ êµ¬ì¡°**:
```json
[
  {
    "input": "Convert the following book chapter...",
    "output": "{\"scene_title\": \"CHAPTER I\", ...}",
    "metadata": {
      "book_id": 1342,
      "chapter_number": 1,
      "chapter_title": "CHAPTER I",
      "input_length": 1850,
      "output_length": 423
    }
  },
  ...
]
```

### 5.2 ì˜ˆìƒ ë°ì´í„°ì…‹ í¬ê¸°

**ê³„ì‚°**:
- ë„ì„œ ìˆ˜: 10ê¶Œ
- í‰ê·  ì±•í„°: 35ê°œ/ê¶Œ
- ì´ ì±•í„°: 350ê°œ

**ì‹¤ì œ (ì²˜ìŒ 5ì±•í„°ë§Œ)**:
- ì²˜ë¦¬ ì±•í„°: 50ê°œ (10ê¶Œ Ã— 5ì±•í„°)
- Train: 40 ìƒ˜í”Œ
- Val: 5 ìƒ˜í”Œ
- Test: 5 ìƒ˜í”Œ

**íŒŒì¼ í¬ê¸°** (ì˜ˆìƒ):
- train_data.json: ~2.5 MB
- val_data.json: ~300 KB
- test_data.json: ~300 KB

---

## 6. í’ˆì§ˆ ê²€ì¦

### 6.1 ìë™ ê²€ì¦

**ì²´í¬ í•­ëª©**:
1. âœ… ëª¨ë“  ìƒ˜í”Œì— ì…ë ¥/ì¶œë ¥ ì¡´ì¬
2. âœ… ì…ë ¥ ê¸¸ì´ > 100ì
3. âœ… ì¶œë ¥ì´ ìœ íš¨í•œ JSON
4. âœ… í•„ìˆ˜ í•„ë“œ ì¡´ì¬ (characters, locations, dialogues)
5. âœ… ë©”íƒ€ë°ì´í„° ì™„ì „ì„±

**ì½”ë“œ**:
```python
def validate_sample(sample):
    assert 'input' in sample
    assert 'output' in sample
    assert len(sample['input']) > 100
    
    output_data = json.loads(sample['output'])
    assert 'scene_title' in output_data
    assert 'characters' in output_data
    # ...
```

### 6.2 ìˆ˜ë™ ê²€ì¦

**ìƒ˜í”Œ ë¦¬ë·°**:
- ëœë¤ 10ê°œ ìƒ˜í”Œ ì¶”ì¶œ
- ì…ë ¥-ì¶œë ¥ ì •í•©ì„± í™•ì¸
- ê°œì²´ëª… ì •í™•ë„ í™•ì¸

**í’ˆì§ˆ ê¸°ì¤€**:
- ì¸ë¬¼ ì¶”ì¶œ ì •í™•ë„: >85%
- ì¥ì†Œ ì¶”ì¶œ ì •í™•ë„: >75%
- ëŒ€í™”ë¬¸ ì¶”ì¶œ ì •í™•ë„: >90%

### 6.3 í†µê³„ ë¶„ì„

**ê³„ì‚° ì§€í‘œ**:
```python
statistics = {
    'total_samples': len(training_samples),
    'avg_input_length': mean(input_lengths),
    'avg_output_length': mean(output_lengths),
    'books_processed': len(unique_book_ids),
    'chapters_processed': total_chapters,
    'avg_chapters_per_book': chapters / books
}
```

---

## 7. ì‹¤í–‰ ë°©ë²•

### 7.1 í™˜ê²½ ì„¤ì •

```bash
# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install requests beautifulsoup4 nltk spacy scikit-learn

# 2. SpaCy ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python -m spacy download en_core_web_sm

# 3. NLTK ë°ì´í„°
python -c "import nltk; nltk.download('punkt')"
```

### 7.2 ë…¸íŠ¸ë¶ ì‹¤í–‰

```bash
# Jupyter Notebook ì‹¤í–‰
jupyter notebook data_preprocessing.ipynb
```

**ì‹¤í–‰ ìˆœì„œ**:
1. ì…€ 1-5: í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
2. ì…€ 6-9: ë°ì´í„° ìˆ˜ì§‘ (GutenbergCollector)
3. ì…€ 10-12: ì „ì²˜ë¦¬ (TextPreprocessor)
4. ì…€ 13-15: ê°œì²´ëª… ì¶”ì¶œ (EntityExtractor)
5. ì…€ 16-18: ìŠ¤í¬ë¦½íŠ¸ ë³€í™˜ (ScriptFormatter)
6. ì…€ 19-21: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
7. ì…€ 22-24: ë°ì´í„°ì…‹ ìƒì„± (DatasetBuilder)
8. ì…€ 25: í†µê³„ ë° ê²€ì¦

### 7.3 ë°°ì¹˜ ì²˜ë¦¬

```python
# ì „ì²´ ë„ì„œ ì²˜ë¦¬
results = pipeline.process_multiple_books(
    book_ids_to_process,
    output_dir='./processed_data'
)

# í•™ìŠµ ë°ì´í„° ìƒì„±
training_samples = dataset_builder.create_training_samples(results)
train, val, test = dataset_builder.split_dataset(training_samples)
dataset_builder.save_datasets(train, val, test)
```

**ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„**:
- ë‹¤ìš´ë¡œë“œ: ~2-5ë¶„ (ìºì‹œ ì—†ì„ ë•Œ)
- ì „ì²˜ë¦¬: ~10-15ë¶„ (10ê¶Œ)
- í•™ìŠµ ë°ì´í„° ìƒì„±: ~1-2ë¶„

**ì´ ì†Œìš” ì‹œê°„**: ì•½ 15-20ë¶„

---

## 8. ë¬¸ì œ í•´ê²°

### 8.1 ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜

#### ì˜¤ë¥˜ 1: `NameError: name 'collector' is not defined`

**ì›ì¸**: ì…€ ì‹¤í–‰ ìˆœì„œ ë¬¸ì œ

**í•´ê²°**:
```python
# GutenbergCollector ì´ˆê¸°í™” ì…€ì„ ë¨¼ì € ì‹¤í–‰
collector = GutenbergCollector()
```

#### ì˜¤ë¥˜ 2: ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

**ì›ì¸**: 
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ
- Gutenberg ì„œë²„ ì ‘ì† ë¶ˆê°€
- ì˜ëª»ëœ Book ID

**í•´ê²°**:
```python
# ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„
book_text = collector.download_book(book_id)

# ë˜ëŠ” ë‹¤ë¥¸ Book ID ì‹œë„
alternative_id = 1342  # Pride and Prejudice (ì•ˆì •ì )
```

#### ì˜¤ë¥˜ 3: `OSError: [E050] Can't find model 'en_core_web_sm'`

**ì›ì¸**: SpaCy ëª¨ë¸ ë¯¸ì„¤ì¹˜

**í•´ê²°**:
```bash
python -m spacy download en_core_web_sm
```

#### ì˜¤ë¥˜ 4: ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì›ì¸**: í° ì±… ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì´ˆê³¼

**í•´ê²°**:
```python
# max_length ì œí•œ
self.nlp.max_length = 500000  # 500KBë¡œ ê°ì†Œ

# ë˜ëŠ” ì±•í„° ìˆ˜ ì œí•œ
chapters = chapters[:3]  # ì²˜ìŒ 3ê°œë§Œ
```

### 8.2 ì„±ëŠ¥ ìµœì í™”

#### ìºì‹œ í™œìš©

```python
# ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸
if os.path.exists('gutenberg_cache'):
    print("ìºì‹œ ì‚¬ìš© ê°€ëŠ¥")
```

#### ë³‘ë ¬ ì²˜ë¦¬ (ì„ íƒ)

```python
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=3) as executor:
    results = list(executor.map(
        pipeline.process_book, 
        book_ids_to_process
    ))
```

### 8.3 ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ

#### ì±•í„° ê°ì§€ ì‹¤íŒ¨

**ì¦ìƒ**: ì±•í„°ê°€ 1ê°œë¡œ ì¸ì‹ë¨

**í•´ê²°**:
1. í…ìŠ¤íŠ¸ ìƒ˜í”Œ í™•ì¸
2. ì±•í„° íŒ¨í„´ í™•ì¸
3. Fallback ë©”ì»¤ë‹ˆì¦˜ ì‚¬ìš©
4. ìˆ˜ë™ ë¶„í•  ê³ ë ¤

#### ê°œì²´ëª… ì¶”ì¶œ ë¶€ì •í™•

**ì¦ìƒ**: ì¸ë¬¼/ì¥ì†Œê°€ ì˜ëª» ì¸ì‹ë¨

**ì›ì¸**: 
- SpaCy ëª¨ë¸ í•œê³„ (ë¬¸í•™ í…ìŠ¤íŠ¸)
- ê³ ìœ ëª…ì‚¬ ë¶ˆëª…í™•

**ê°œì„ **:
- ë” í° ëª¨ë¸ ì‚¬ìš© (`en_core_web_md`, `en_core_web_lg`)
- í›„ì²˜ë¦¬ í•„í„°ë§
- ë¹ˆë„ìˆ˜ ê¸°ë°˜ í•„í„°ë§

---

## 9. ë‹¤ìŒ ë‹¨ê³„

### 9.1 ëª¨ë¸ ì„ íƒ

**ì¶”ì²œ ëª¨ë¸**:
1. **T5-base** (ì£¼ë ¥)
   - Text-to-Text ë³€í™˜ì— ìµœì 
   - 220M íŒŒë¼ë¯¸í„°
   - Seq2Seq ì•„í‚¤í…ì²˜

2. **BART-base** (ëŒ€ì•ˆ)
   - í…ìŠ¤íŠ¸ ìƒì„± ê°•ì 
   - 140M íŒŒë¼ë¯¸í„°

3. **GPT-2** (ë² ì´ìŠ¤ë¼ì¸)
   - ë¹ ë¥¸ í•™ìŠµ
   - 117M íŒŒë¼ë¯¸í„°

### 9.2 Fine-tuning ì¤€ë¹„

```python
from transformers import T5ForConditionalGeneration, T5Tokenizer

# ëª¨ë¸ ë¡œë“œ
model = T5ForConditionalGeneration.from_pretrained('t5-base')
tokenizer = T5Tokenizer.from_pretrained('t5-base')

# ë°ì´í„° ë¡œë“œ
import json
with open('train_data.json', 'r') as f:
    train_data = json.load(f)

# í† í°í™”
train_encodings = tokenizer(
    [s['input'] for s in train_data],
    truncation=True,
    padding=True,
    max_length=512
)
```

### 9.3 í•™ìŠµ ê³„íš

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
- Learning rate: 5e-5
- Batch size: 4 (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼)
- Epochs: 3-5
- Warmup steps: 500

**ì˜ˆìƒ í•™ìŠµ ì‹œê°„**:
- Tesla T4 GPU: ~2-3ì‹œê°„
- CPU: ~10-15ì‹œê°„

---

## 10. ì°¸ê³  ìë£Œ

### 10.1 ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ

- SpaCy: https://spacy.io/
- NLTK: https://www.nltk.org/
- Transformers: https://huggingface.co/docs/transformers/

### 10.2 í•™ìˆ  ìë£Œ

- BLEU Score: Papineni et al. (2002)
- NER: Sang & De Meulder (2003)
- T5: Raffel et al. (2020)

### 10.3 ê´€ë ¨ í”„ë¡œì íŠ¸

- Gutenberg API: https://github.com/c-w/gutenberg
- Book-to-Script: [ì´ í”„ë¡œì íŠ¸]

---

## ë¶€ë¡ A: ì „ì²´ í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

```
GutenbergCollector
â”œâ”€â”€ download_book()
â””â”€â”€ cache_dir

TextPreprocessor
â”œâ”€â”€ remove_gutenberg_header_footer()
â”œâ”€â”€ remove_table_of_contents()
â”œâ”€â”€ clean_text()
â”œâ”€â”€ split_into_chapters()
â””â”€â”€ _fallback_chapter_split()

EntityExtractor
â”œâ”€â”€ extract_entities()
â”œâ”€â”€ get_main_characters()
â””â”€â”€ get_main_locations()

ScriptFormatter
â”œâ”€â”€ extract_dialogues()
â”œâ”€â”€ extract_narrative()
â””â”€â”€ create_scene_structure()

BookToScriptPipeline
â”œâ”€â”€ collector: GutenbergCollector
â”œâ”€â”€ preprocessor: TextPreprocessor
â”œâ”€â”€ extractor: EntityExtractor
â”œâ”€â”€ formatter: ScriptFormatter
â”œâ”€â”€ process_book()
â””â”€â”€ process_multiple_books()

DatasetBuilder
â”œâ”€â”€ create_training_samples()
â”œâ”€â”€ split_dataset()
â””â”€â”€ save_datasets()

EvaluationMetrics
â”œâ”€â”€ calculate_bleu()
â””â”€â”€ calculate_bleu_variants()
```

---

## ë¶€ë¡ B: ë°ì´í„° ì˜ˆì‹œ

### ì…ë ¥ ì˜ˆì‹œ (Pride and Prejudice, Chapter 1)

```
Convert the following book chapter into a video script format. 
Extract key elements including characters, locations, dialogues, and narrative descriptions.

Chapter: CHAPTER I

Text:
It is a truth universally acknowledged, that a single man in possession
of a good fortune, must be in want of a wife.

However little known the feelings or views of such a man may be on his
first entering a neighbourhood, this truth is so well fixed in the minds
of the surrounding families, that he is considered the rightful property
of some one or other of their daughters.

"My dear Mr. Bennet," said his lady to him one day, "have you heard that
Netherfield Park is let at last?"

Mr. Bennet replied that he had not.

"But it is," returned she; "for Mrs. Long has just been here, and she
told me all about it."
...
```

### ì¶œë ¥ ì˜ˆì‹œ

```json
{
  "scene_title": "CHAPTER I",
  "characters": [
    "Mr. Bennet",
    "Mrs. Bennet",
    "Mrs. Long"
  ],
  "locations": [
    "Netherfield Park"
  ],
  "dialogues": [
    "My dear Mr. Bennet, have you heard that Netherfield Park is let at last?",
    "But it is, for Mrs. Long has just been here, and she told me all about it."
  ],
  "narrative": "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters. Mr. Bennet replied that he had not.",
  "total_sentences": 45,
  "total_dialogues": 12
}
```

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025ë…„ 10ì›” 14ì¼
