# 프로젝트 워크플로우 다이어그램

## 🔄 전체 프로세스 흐름

```
┌─────────────────────────────────────────────────────────────────┐
│                     프로젝트 목표                                │
│     도서 텍스트 → 비디오 스크립트 변환 LLM 모델 개발            │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│                  Phase 1: 데이터 전처리                          │
│                   (현재 단계, ~ 10/27)                           │
└─────────────────────────────────────────────────────────────────┘
                              ↓
    ┌─────────────────────────────────────────────┐
    │         1. 데이터 수집 (Data Collection)    │
    │   Project Gutenberg, 국내 디지털 도서관     │
    └─────────────────────────────────────────────┘
                      ↓
    ┌─────────────────────────────────────────────┐
    │      2. 텍스트 정제 (Text Cleaning)         │
    │    - Gutenberg 헤더/푸터 제거               │
    │    - 공백 정규화                             │
    │    - 챕터 분할                               │
    └─────────────────────────────────────────────┘
                      ↓
    ┌─────────────────────────────────────────────┐
    │    3. 개체명 추출 (Entity Extraction)       │
    │    - 인물 (PERSON)                           │
    │    - 장소 (GPE, LOC)                         │
    │    - 시간 (DATE, TIME)                       │
    └─────────────────────────────────────────────┘
                      ↓
    ┌─────────────────────────────────────────────┐
    │   4. 스크립트 구조화 (Script Formatting)    │
    │    - 대화문 추출                             │
    │    - 서술 분리                               │
    │    - 장면 구조 생성                          │
    └─────────────────────────────────────────────┘
                      ↓
    ┌─────────────────────────────────────────────┐
    │   5. 데이터셋 구축 (Dataset Creation)       │
    │    - Train/Val/Test 분할 (80/10/10)        │
    │    - JSON 포맷으로 저장                      │
    └─────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────────────────┐
│                  Phase 2: 모델링 (~ 11/10)                       │
│          - LLM 선택 (T5/BART/GPT-2)                              │
│          - Fine-tuning                                           │
│          - 최적화                                                │
└─────────────────────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────────────────┐
│              Phase 3: 성능 평가 (~ 12/03)                        │
│          - BLEU Score                                            │
│          - FVD (선택)                                            │
│          - CLIPScore (선택)                                      │
└─────────────────────────────────────────────────────────────────┘
```

---

## 📊 데이터 전처리 세부 흐름

```
원본 도서 (Project Gutenberg)
        │
        ├─→ [다운로드] book_1342.txt (Pride and Prejudice)
        ├─→ [다운로드] book_84.txt (Frankenstein)
        ├─→ [다운로드] book_98.txt (A Tale of Two Cities)
        └─→ ... (50+ books)
        │
        ↓
┌───────────────────────────────────────┐
│      TextPreprocessor                 │
│  1. Gutenberg 헤더/푸터 제거          │
│  2. 텍스트 정제                        │
│  3. 챕터 분할                          │
└───────────────────────────────────────┘
        │
        ↓
┌───────────────────────────────────────┐
│      EntityExtractor                  │
│  - SpaCy NER                           │
│  - 인물: ["Elizabeth", "Darcy", ...]   │
│  - 장소: ["London", "Netherfield", ...]│
│  - 시간: ["morning", "1813", ...]      │
└───────────────────────────────────────┘
        │
        ↓
┌───────────────────────────────────────┐
│      ScriptFormatter                  │
│  - 대화문: ["Hello", "How are you"]    │
│  - 서술: "He walked into the room..."  │
│  - 장면: {characters, location, ...}   │
└───────────────────────────────────────┘
        │
        ↓
학습 데이터셋
        │
        ├─→ train_data.json (80%)
        ├─→ val_data.json (10%)
        └─→ test_data.json (10%)
```

---

## 👥 역할 분담 및 협업 구조

```
┌─────────────────────────────────────────────────────────────┐
│                        팀 전체                              │
│                (모든 프로세스 함께 경험)                    │
└─────────────────────────────────────────────────────────────┘
                          ↓
        ┌─────────────────────────────────────┐
        │        병렬 작업 (Parallel)         │
        └─────────────────────────────────────┘
                          ↓
    ┌─────────────┐              ┌──────────────────┐
    │ 역할 A (1명)│              │ 역할 B (나머지)  │
    │ 데이터 수집 │              │ 프레임워크 셋업  │
    └─────────────┘              └──────────────────┘
          ↓                              ↓
    • 도서 다운로드            • 파이프라인 최적화
    • 장르 다양화              • 품질 검증
    • 백업 관리                • 모델 조사
    • 60% 시간                 • 40% 시간
          ↓                              ↓
    ┌─────────────────────────────────────────┐
    │         합류: 품질 검증 및 구축          │
    │         (목요일 ~ 금요일)                │
    └─────────────────────────────────────────┘
```

---

## 🗓️ 일정 타임라인

```
Week 1: 데이터 전처리 초기
┌──────┬──────┬──────┬──────┬──────┬──────┬──────┐
│ 월   │ 화   │ 수   │ 목   │ 금   │ 토   │ 일   │
├──────┼──────┼──────┼──────┼──────┼──────┼──────┤
│ 환경 │ 수집 │ 대규모│ 품질 │ 데이터│ 문서 │ 정리 │
│ 설정 │ 시작 │ 처리 │ 검증 │ 구축 │ 화   │      │
├──────┼──────┼──────┼──────┼──────┼──────┼──────┤
│ 10권 │ 25권 │ 40권 │ 50권 │학습   │보고서│ 휴식 │
│      │      │      │      │데이터 │      │      │
└──────┴──────┴──────┴──────┴──────┴──────┴──────┘
   ↓      ↓      ↓      ↓      ↓
  체크포인트 1  체크포인트 2  체크포인트 3

Week 2: 데이터 정제 고도화 (10/19 - 10/27)
└─→ 알고리즘 개선, 모델링 준비
```

---

## 🔧 기술 스택

```
┌─────────────────────────────────────────────────────────┐
│                   Infrastructure                        │
│  • Python 3.12.11                                       │
│  • PyTorch 2.8.0+cu126                                  │
│  • GPU: Tesla T4 (CUDA)                                 │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│                  NLP Libraries                          │
│  • SpaCy (Entity Extraction)                            │
│  • NLTK (Tokenization, BLEU)                            │
│  • Transformers (Model Loading)                         │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│                  Data Processing                        │
│  • BeautifulSoup (HTML Parsing)                         │
│  • Requests (HTTP Requests)                             │
│  • Pandas, NumPy (Data Manipulation)                    │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│                  Development Tools                      │
│  • Jupyter Notebook (Interactive Development)           │
│  • Git (Version Control)                                │
│  • track_progress.py (Progress Tracking)                │
└─────────────────────────────────────────────────────────┘
```

---

## 📂 파일 구조

```
AI_lab/
│
├── 📓 작업 노트북
│   ├── data_preprocessing.ipynb ⭐⭐⭐ (메인 작업)
│   ├── week2.ipynb (환경 확인)
│   └── ...
│
├── 📚 문서
│   ├── README.md (프로젝트 개요)
│   ├── PROJECT_SUMMARY.md ⭐⭐⭐ (전체 요약)
│   ├── HOW_TO_PROCEED.md ⭐⭐⭐ (실행 계획)
│   ├── QUICK_START.md ⭐⭐ (빠른 시작)
│   ├── WEEKLY_TIMELINE.md ⭐⭐ (주간 일정)
│   ├── DATA_PREPROCESSING_GUIDE.md ⭐ (상세 가이드)
│   └── WORKFLOW.md (이 파일)
│
├── 🔧 도구
│   └── track_progress.py (진행 추적)
│
├── 📁 데이터 (생성될 폴더)
│   ├── raw_data/ (원본 도서)
│   ├── processed_data/ (전처리 완료)
│   ├── train_data.json
│   ├── val_data.json
│   └── test_data.json
│
└── 📊 로그 (생성될 파일)
    ├── progress_tracker.json
    ├── processing_log.json
    ├── final_report.json
    └── daily_report_*.md
```

---

## 🎯 성공 지표

```
데이터 수집
├── 목표: 50권 ──────────────────────────── ✅
├── 다양성: 3개 장르 이상 ────────────────── ✅
└── 품질: 다운로드 성공률 90% 이상 ─────── ✅

데이터 전처리
├── 챕터 분할 정확도: 80% 이상 ──────────── ✅
├── 개체명 추출: 주요 인물 90% 이상 ──────── ✅
└── 결측치: 5% 미만 ─────────────────────── ✅

데이터셋 품질
├── 학습 샘플: 최소 300개 ───────────────── ✅
├── 평균 챕터 길이: 1000 단어 이상 ───────── ✅
└── 문법 오류: 5% 미만 ──────────────────── ✅
```

---

## 💡 핵심 원칙

```
1. 작은 단계로 진행
   └─→ 샘플 테스트 → 소규모 적용 → 대규모 실행

2. 정기적인 검증
   └─→ 매일 진행 상황 확인 → 문제 조기 발견

3. 병렬 작업
   └─→ 데이터 수집 + 프레임워크 = 시간 절약

4. 문서화
   └─→ 모든 결정 기록 → 재현 가능성 확보

5. 팀 커뮤니케이션
   └─→ 매일 공유 → 정기 회의 → 문제 해결
```

---

## 🚀 시작 명령어

```bash
# 1. 저장소 확인
cd /path/to/AI_lab

# 2. 환경 확인
python track_progress.py --check

# 3. 노트북 실행
jupyter notebook data_preprocessing.ipynb

# 4. 진행 상황 기록
python track_progress.py --log "Started data collection"
```

---

**📌 이 다이어그램을 참고하여 프로젝트의 전체 흐름을 이해하세요!**

**👉 다음: `PROJECT_SUMMARY.md` 또는 `HOW_TO_PROCEED.md` 읽기**
