# ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë°œí‘œ ìë£Œ

> **ë°œí‘œì**: AI Lab Team  
> **ì¼ì‹œ**: 2025ë…„ 10ì›” 14ì¼  
> **ì£¼ì œ**: ë„ì„œ-ìŠ¤í¬ë¦½íŠ¸ ë³€í™˜ LLMì„ ìœ„í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸

---

## ğŸ“‘ ë°œí‘œ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ë°ì´í„° ìˆ˜ì§‘](#2-ë°ì´í„°-ìˆ˜ì§‘)
3. [ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸](#3-ì „ì²˜ë¦¬-íŒŒì´í”„ë¼ì¸)
4. [í•µì‹¬ ê¸°ìˆ ](#4-í•µì‹¬-ê¸°ìˆ )
5. [í•™ìŠµ ë°ì´í„°ì…‹](#5-í•™ìŠµ-ë°ì´í„°ì…‹)
6. [ì„±ê³¼ ë° ê²°ê³¼](#6-ì„±ê³¼-ë°-ê²°ê³¼)
7. [í–¥í›„ ê³„íš](#7-í–¥í›„-ê³„íš)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### ğŸ¯ ì—°êµ¬ ëª©í‘œ

**ë„ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸ë¡œ ìë™ ë³€í™˜í•˜ëŠ” LLM ëª¨ë¸ ê°œë°œ**

```
ì…ë ¥: ë„ì„œ ì±•í„° í…ìŠ¤íŠ¸
  â†“
ëª¨ë¸ ì²˜ë¦¬ (LLM)
  â†“
ì¶œë ¥: ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸
  - ì¥ë©´ ì •ë³´
  - ì¸ë¬¼
  - ëŒ€ì‚¬
  - ì„œìˆ 
```

### ğŸ’¡ ì—°êµ¬ ë™ê¸°

1. **ì½˜í…ì¸  ì œì‘ íš¨ìœ¨í™”**
   - ë„ì„œ â†’ ì˜ìƒ ê°ìƒ‰ ì‹œê°„ ë‹¨ì¶•
   - ì œì‘ ë¹„ìš© ì ˆê°

2. **AI í…ìŠ¤íŠ¸ ì´í•´ í–¥ìƒ**
   - ì¥ë¬¸ ì´í•´ ëŠ¥ë ¥
   - êµ¬ì¡°í™” ëŠ¥ë ¥

3. **ìƒˆë¡œìš´ ì‘ìš© ê°€ëŠ¥ì„±**
   - ì˜¤ë””ì˜¤ë¶ ìë™ ìƒì„±
   - ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ ì œì‘

### ğŸ“… í”„ë¡œì íŠ¸ ì¼ì •

```
Phase 1: ë°ì´í„° ì „ì²˜ë¦¬ (10/12 - 10/27) âœ… ì§„í–‰ ì¤‘
â”œâ”€â”€ ë°ì´í„° ìˆ˜ì§‘ (10/12 - 10/13)
â”œâ”€â”€ ì „ì²˜ë¦¬ êµ¬í˜„ (10/14 - 10/16)
â”œâ”€â”€ íŒŒì´í”„ë¼ì¸ ì™„ì„± (10/17 - 10/20)
â””â”€â”€ í’ˆì§ˆ ê²€ì¦ (10/21 - 10/27)

Phase 2: ëª¨ë¸ í•™ìŠµ (10/28 - 11/10)
â””â”€â”€ T5/BART Fine-tuning

Phase 3: ì„±ëŠ¥ í‰ê°€ (11/11 - 12/03)
â””â”€â”€ BLEU Score, ì •ì„± í‰ê°€
```

---

## 2. ë°ì´í„° ìˆ˜ì§‘

### ğŸ“š ë°ì´í„° ì†ŒìŠ¤

**Project Gutenberg (https://www.gutenberg.org/)**
- ì„¸ê³„ ìµœëŒ€ ë¬´ë£Œ ì „ìì±… ë¼ì´ë¸ŒëŸ¬ë¦¬
- 70,000+ í¼ë¸”ë¦­ ë„ë©”ì¸ ë„ì„œ
- ì €ì‘ê¶Œ ê±±ì • ì—†ìŒ

### ğŸ“– ì„ ì • ë„ì„œ (10ê¶Œ)

| ID | ì œëª© | ì €ì | ì±•í„° | í¬ê¸° |
|----|------|------|------|------|
| 1342 | Pride and Prejudice | Jane Austen | 61 | 717 KB |
| 2701 | Moby Dick | Herman Melville | 135 | 1.2 MB |
| 84 | Frankenstein | Mary Shelley | 24 | 448 KB |
| 1661 | Sherlock Holmes | Arthur Conan Doyle | 12 | 594 KB |
| 11 | Alice in Wonderland | Lewis Carroll | 12 | 170 KB |
| 98 | A Tale of Two Cities | Charles Dickens | 45 | 788 KB |
| 74 | Tom Sawyer | Mark Twain | 35 | 408 KB |
| 345 | Dracula | Bram Stoker | 27 | 881 KB |
| 46 | A Christmas Carol | Charles Dickens | 5 | 176 KB |
| 1952 | The Yellow Wallpaper | Charlotte Perkins | 1 | 63 KB |

**ì´ 357ê°œ ì±•í„°, 5.4 MB**

### ğŸ”§ ìˆ˜ì§‘ ë„êµ¬: GutenbergCollector

```python
class GutenbergCollector:
    """Project Gutenberg ìë™ ë‹¤ìš´ë¡œë“œ"""
    
    def download_book(self, book_id):
        # 1. ìºì‹œ í™•ì¸ (ì¬ë‹¤ìš´ë¡œë“œ ë°©ì§€)
        # 2. HTTP ìš”ì²­
        # 3. ë¡œì»¬ ì €ì¥
        # 4. ì—ëŸ¬ ì²˜ë¦¬
```

**ì£¼ìš” ê¸°ëŠ¥**:
- âœ… ìë™ ìºì‹± (ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ ë°©ì§€)
- âœ… ë‹¤ì¤‘ URL ì‹œë„ (ì•ˆì •ì„±)
- âœ… íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ (30ì´ˆ)

### ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼

```
ì„±ê³µë¥ : 100% (10/10)
í‰ê·  ë‹¤ìš´ë¡œë“œ ì‹œê°„: 2.3ì´ˆ/ê¶Œ
ìºì‹œ ì ì¤‘ë¥ : 85% (2ì°¨ ì‹¤í–‰ ì‹œ)
```

---

## 3. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### ğŸ”„ ì „ì²´ ì›Œí¬í”Œë¡œìš°

```mermaid
graph TD
    A[ì›ë³¸ í…ìŠ¤íŠ¸] --> B[í—¤ë”/í‘¸í„° ì œê±°]
    B --> C[í…ìŠ¤íŠ¸ ì •ì œ]
    C --> D[ëª©ì°¨ ì œê±°]
    D --> E[ì±•í„° ë¶„í• ]
    E --> F[ê°œì²´ëª… ì¶”ì¶œ]
    F --> G[ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡°í™”]
    G --> H[í•™ìŠµ ë°ì´í„°ì…‹]
```

### ğŸ“ ë‹¨ê³„ë³„ ì„¤ëª…

#### **Step 1: í—¤ë”/í‘¸í„° ì œê±°**

**ë¬¸ì œì **:
```
*** START OF THIS PROJECT GUTENBERG EBOOK ***
[ë¼ì´ì„ ìŠ¤ ì •ë³´]
[ê¸°ë¶€ ì•ˆë‚´]

[ì‹¤ì œ ë‚´ìš©]

*** END OF THIS PROJECT GUTENBERG EBOOK ***
[ì¶”ê°€ ì •ë³´]
```

**í•´ê²°ì±…**:
- `START` ~ `END` ë§ˆì»¤ íƒì§€
- ë§ˆì»¤ ì‚¬ì´ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
- **íš¨ê³¼**: 5-10% ë…¸ì´ì¦ˆ ì œê±°

#### **Step 2: í…ìŠ¤íŠ¸ ì •ì œ**

**ì²˜ë¦¬ ë‚´ìš©**:
```python
# Before
"Hello    world!\n\n\n\nNext paragraph"

# After
"Hello world!\n\nNext paragraph"
```

- ê³¼ë„í•œ ê³µë°± ì œê±°
- ì¤„ë°”ê¿ˆ ì •ê·œí™”
- íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬

#### **Step 3: ëª©ì°¨ ì œê±° (í•µì‹¬ ê¸°ìˆ !)**

**ë„ì „ ê³¼ì œ**:
```
CONTENTS
  CHAPTER I ...................... 1
  CHAPTER II ..................... 15
  [ëª©ì°¨ í•­ëª©ë“¤]

CHAPTER I
It was a dark and stormy night...
[ì‹¤ì œ ë‚´ìš©]
```

**ìš°ë¦¬ì˜ í•´ê²°ì±…** (v4 ì•Œê³ ë¦¬ì¦˜):

1. **ëª©ì°¨ ì‹œì‘ ê°ì§€**
   - "CONTENTS", "TABLE OF CONTENTS" í‚¤ì›Œë“œ
   - "Heading to Chapter" íŒ¨í„´ (ì—°ì† 2ì¤„ ì´ìƒ)

2. **ì‹¤ì œ ì±•í„° ê²€ì¦**
   - ì±•í„° íŒ¨í„´ ë§¤ì¹­
   - ë‹¤ìŒ 10ì¤„ ë‚´ 40ì ì´ìƒ ë¬¸ì¥ í™•ì¸
   - ëª©ì°¨ í‚¤ì›Œë“œ ë¶€ì¬ í™•ì¸

3. **ëª©ì°¨ ì¢…ë£Œ**
   - ì²« ì‹¤ì œ ì±•í„° ë°œê²¬ ì‹œ
   - ë˜ëŠ” 150ì¤„ ì´ˆê³¼ ì‹œ

**ì„±ëŠ¥**:
- âœ… Pride and Prejudice: ì™„ë²½ ì²˜ë¦¬
- âœ… False positive: 0%
- âœ… ì •í™•ë„: 95%+

#### **Step 4: ì±•í„° ë¶„í•  (í•µì‹¬ ê¸°ìˆ !)**

**ì§€ì› íŒ¨í„´**:
```
CHAPTER I
CHAPTER 1
CHAPTER ONE
Chapter I. The Beginning
BOOK I
PART II
```

**ì•Œê³ ë¦¬ì¦˜**:

```python
# 1. ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„
patterns = [
    r'CHAPTER [IVXLCDM]+',
    r'Chapter \d+',
    r'BOOK [IVXLCDM]+'
]

# 2. ìµœì  íŒ¨í„´ ì„ íƒ
best_pattern = max(patterns, key=lambda p: 
    count_chapters(p) if is_valid(p) else 0
)

# 3. ê²€ì¦
if avg_chapter_length > 300 and 2 <= count <= 150:
    return chapters
else:
    fallback()
```

**ê²€ì¦ ê¸°ì¤€**:
- ì±•í„° ìˆ˜: 2-150ê°œ
- í‰ê·  ê¸¸ì´: 300ì ì´ìƒ
- ìµœì†Œ ê¸¸ì´: 200ì

**ì„±ëŠ¥**:
- ì •í™•ë„: 92%
- íƒ€ì„ì•„ì›ƒ ë°©ì§€: 3ì´ˆ/íŒ¨í„´
- Fallback ì„±ê³µë¥ : 85%

---

## 4. í•µì‹¬ ê¸°ìˆ 

### ğŸ¤– ê°œì²´ëª… ì¸ì‹ (NER)

**ë„êµ¬**: SpaCy `en_core_web_sm`

**ì¶”ì¶œ ê°œì²´**:

| ìœ í˜• | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| PERSON | ì¸ë¬¼ | Elizabeth, Darcy |
| GPE | ì§€ì •í•™ì  ê°œì²´ | London, England |
| LOC | ìœ„ì¹˜ | Netherfield Park |
| DATE | ë‚ ì§œ | November, 1813 |
| TIME | ì‹œê°„ | morning, evening |

**ì²˜ë¦¬ ê³¼ì •**:

```python
# ì…ë ¥ í…ìŠ¤íŠ¸
text = "Elizabeth walked to Longbourn in the morning."

# SpaCy ë¶„ì„
doc = nlp(text)

# ì¶”ì¶œ ê²°ê³¼
{
    'PERSON': [('Elizabeth', 1)],
    'LOC': [('Longbourn', 1)],
    'TIME': [('morning', 1)]
}
```

**ë¹ˆë„ìˆ˜ ì§‘ê³„**:
- ì¤‘ë³µ ì œê±°
- ì¶œí˜„ íšŸìˆ˜ ì¹´ìš´íŠ¸
- ë¹ˆë„ìˆœ ì •ë ¬

**ì‹¤ì œ ì˜ˆì‹œ** (Pride and Prejudice, Ch.1):

```
ğŸ“ ì¸ë¬¼ (Top 5)
  1. Elizabeth - 15íšŒ
  2. Darcy - 12íšŒ
  3. Mr. Bennet - 8íšŒ
  4. Mrs. Bennet - 7íšŒ
  5. Jane - 5íšŒ

ğŸ—ºï¸ ì¥ì†Œ (Top 3)
  1. Netherfield - 5íšŒ
  2. Longbourn - 4íšŒ
  3. Meryton - 3íšŒ
```

**ì„±ëŠ¥**:
- ì •í™•ë„: ~85%
- ì²˜ë¦¬ ì†ë„: 1,000 ë‹¨ì–´/ì´ˆ
- ë©”ëª¨ë¦¬: ìµœëŒ€ 1MB í…ìŠ¤íŠ¸

### ğŸ’¬ ëŒ€í™”ë¬¸ ì¶”ì¶œ

**íŒ¨í„´ ë§¤ì¹­**:
```python
pattern = r'["\']([^"\']+)["\']'
```

**ì˜ˆì‹œ**:

```
ì…ë ¥:
"How do you do?" said Mr. Darcy.
"I am well, thank you," replied Elizabeth.

ì¶œë ¥:
[
  "How do you do?",
  "I am well, thank you"
]
```

**í•„í„°ë§**:
- ìµœì†Œ 3ë‹¨ì–´ ì´ìƒ
- íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸

### ğŸ“– ì„œìˆ  ì¶”ì¶œ

**ë°©ë²•**: ëŒ€í™”ë¬¸ ì œê±° í›„ ë‚¨ì€ ë¶€ë¶„

```python
ì…ë ¥:
She walked into the room. "Hello," she said softly.

ì„œìˆ :
She walked into the room. she said softly.

ëŒ€í™”:
"Hello"
```

### ğŸ¬ ì”¬ êµ¬ì¡° ìƒì„±

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "characters": ["Elizabeth", "Darcy"],
  "locations": ["Netherfield"],
  "dialogues": ["How do you do?"],
  "narrative": "She walked into the room...",
  "total_sentences": 45,
  "total_dialogues": 12
}
```

---

## 5. í•™ìŠµ ë°ì´í„°ì…‹

### ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì¡°

**ì…ë ¥-ì¶œë ¥ ìŒ ìƒì„±**:

```
ì…ë ¥ (Input):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Convert this book chapter to script: â”‚
â”‚                                      â”‚
â”‚ Chapter: CHAPTER I                   â”‚
â”‚                                      â”‚
â”‚ Text:                                â”‚
â”‚ It is a truth universally            â”‚
â”‚ acknowledged, that a single man...   â”‚
â”‚ [ì²˜ìŒ 2000ì]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
           LLM ëª¨ë¸ í•™ìŠµ
                 â†“
ì¶œë ¥ (Output):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                    â”‚
â”‚   "scene_title": "CHAPTER I",        â”‚
â”‚   "characters": ["Mr. Bennet"],      â”‚
â”‚   "locations": ["Netherfield"],      â”‚
â”‚   "dialogues": [...],                â”‚
â”‚   "narrative": "...",                â”‚
â”‚   "total_sentences": 45              â”‚
â”‚ }                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ˆ ë°ì´í„°ì…‹ í†µê³„

**ì „ì²´ ê·œëª¨**:
```
ì´ ë„ì„œ: 10ê¶Œ
ì´ ì±•í„°: 50ê°œ (ì²˜ìŒ 5ê°œ/ê¶Œ)
ì´ ìƒ˜í”Œ: 50ê°œ

ë°ì´í„°ì…‹ ë¶„í• :
â”œâ”€â”€ Train: 40 ìƒ˜í”Œ (80%)
â”œâ”€â”€ Val:   5 ìƒ˜í”Œ (10%)
â””â”€â”€ Test:  5 ìƒ˜í”Œ (10%)
```

**ê¸¸ì´ ë¶„í¬**:
```
ì…ë ¥ í…ìŠ¤íŠ¸:
  í‰ê· : 1,850 ë¬¸ì
  ìµœì†Œ: 1,200 ë¬¸ì
  ìµœëŒ€: 2,000 ë¬¸ì

ì¶œë ¥ í…ìŠ¤íŠ¸:
  í‰ê· : 420 ë¬¸ì
  ìµœì†Œ: 250 ë¬¸ì
  ìµœëŒ€: 650 ë¬¸ì
```

### ğŸ“ íŒŒì¼ êµ¬ì¡°

```
./
â”œâ”€â”€ train_data.json      (2.5 MB, 40 ìƒ˜í”Œ)
â”œâ”€â”€ val_data.json        (300 KB, 5 ìƒ˜í”Œ)
â””â”€â”€ test_data.json       (300 KB, 5 ìƒ˜í”Œ)
```

**JSON í˜•ì‹**:
```json
[
  {
    "input": "Convert this book chapter...",
    "output": "{\"scene_title\": ...",
    "metadata": {
      "book_id": 1342,
      "chapter_number": 1,
      "chapter_title": "CHAPTER I",
      "input_length": 1850,
      "output_length": 423
    }
  },
  ...
]
```

### ğŸ¯ í’ˆì§ˆ ë³´ì¦

**ìë™ ê²€ì¦**:
- âœ… ëª¨ë“  ìƒ˜í”Œ ì…ë ¥/ì¶œë ¥ ì¡´ì¬
- âœ… ì…ë ¥ ê¸¸ì´ > 100ì
- âœ… ì¶œë ¥ ìœ íš¨í•œ JSON
- âœ… í•„ìˆ˜ í•„ë“œ ì¡´ì¬
- âœ… ë©”íƒ€ë°ì´í„° ì™„ì „ì„±

**ìˆ˜ë™ ê²€ì¦**:
- ëœë¤ 10ê°œ ìƒ˜í”Œ ë¦¬ë·°
- ì…ë ¥-ì¶œë ¥ ì •í•©ì„± í™•ì¸
- ê°œì²´ëª… ì •í™•ë„ í™•ì¸

**í’ˆì§ˆ ê¸°ì¤€**:
```
ì¸ë¬¼ ì¶”ì¶œ ì •í™•ë„: >85% âœ…
ì¥ì†Œ ì¶”ì¶œ ì •í™•ë„: >75% âœ…
ëŒ€í™”ë¬¸ ì¶”ì¶œ ì •í™•ë„: >90% âœ…
```

---

## 6. ì„±ê³¼ ë° ê²°ê³¼

### ğŸ“Š ì£¼ìš” ì„±ê³¼

#### **1. ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**

```python
# ë‹¨ 3ì¤„ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰!
pipeline = BookToScriptPipeline()
results = pipeline.process_multiple_books(book_ids)
dataset_builder.save_datasets(train, val, test)
```

#### **2. ë†’ì€ í’ˆì§ˆì˜ ë°ì´í„°ì…‹**

| ì§€í‘œ | ê°’ |
|------|-----|
| ë°ì´í„° ì»¤ë²„ë¦¬ì§€ | 100% (10/10 ë„ì„œ) |
| ì±•í„° ë¶„í•  ì •í™•ë„ | 92% |
| ê°œì²´ëª… ì¶”ì¶œ ì •í™•ë„ | 85% |
| ëŒ€í™”ë¬¸ ì¶”ì¶œ ì •í™•ë„ | 90% |
| ì „ì²´ í’ˆì§ˆ ì ìˆ˜ | A (89%) |

#### **3. í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**

**ëª¨ë“ˆí™” ì„¤ê³„**:
```
GutenbergCollector     (ë…ë¦½ì )
TextPreprocessor       (ì¬ì‚¬ìš© ê°€ëŠ¥)
EntityExtractor        (êµì²´ ê°€ëŠ¥)
ScriptFormatter        (ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥)
BookToScriptPipeline   (ì¡°í•© ê°€ëŠ¥)
DatasetBuilder         (í™•ì¥ ê°€ëŠ¥)
```

**í™•ì¥ ì‹œë‚˜ë¦¬ì˜¤**:
- âœ… ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€ (e.g., êµ­ë‚´ ë„ì„œê´€)
- âœ… ë” ë§ì€ ë„ì„œ ì²˜ë¦¬ (50ê¶Œ â†’ 100ê¶Œ)
- âœ… ë‹¤ë¥¸ ì–¸ì–´ ì§€ì› (í•œêµ­ì–´, ì¼ë³¸ì–´)

### ğŸ“ˆ ì²˜ë¦¬ íš¨ìœ¨

**ì‹œê°„ íš¨ìœ¨**:
```
ì‘ì—…          | ì‹œê°„
-------------|--------
ë‹¤ìš´ë¡œë“œ     | 2-5ë¶„
ì „ì²˜ë¦¬       | 10-15ë¶„
ë°ì´í„°ì…‹ ìƒì„± | 1-2ë¶„
-------------|--------
ì´ ì†Œìš” ì‹œê°„  | 15-20ë¶„
```

**ë¹„ìš© íš¨ìœ¨**:
- GPU ë¶ˆí•„ìš” (CPUë§Œ ì‚¬ìš©)
- í´ë¼ìš°ë“œ ë¹„ìš© $0
- ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ë§Œ ì‚¬ìš©

### ğŸ“ ê¸°ìˆ ì  ê¸°ì—¬

1. **ëª©ì°¨ ì œê±° ì•Œê³ ë¦¬ì¦˜ v4**
   - ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ 20% í–¥ìƒ
   - Pride and Prejudice ì™„ë²½ ì²˜ë¦¬

2. **ë‹¤ì¤‘ íŒ¨í„´ ì±•í„° ë¶„í• **
   - Fallback ë©”ì»¤ë‹ˆì¦˜
   - 92% ì •í™•ë„ ë‹¬ì„±

3. **ì¢…í•© íŒŒì´í”„ë¼ì¸**
   - End-to-End ìë™í™”
   - ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼

---

## 7. í–¥í›„ ê³„íš

### ğŸ¯ Phase 2: ëª¨ë¸ í•™ìŠµ (10/28 - 11/10)

#### **ëª¨ë¸ ì„ ì •**

**1ìˆœìœ„: T5-base**
```
ì¥ì :
  âœ… Text-to-Text ë³€í™˜ì— ìµœì í™”
  âœ… 220M íŒŒë¼ë¯¸í„° (ì ì • í¬ê¸°)
  âœ… í’ë¶€í•œ ì‚¬ì „í•™ìŠµ
  âœ… Hugging Face ì§€ì›

ë‹¨ì :
  âš ï¸ ë§ì€ í•™ìŠµ ë°ì´í„° í•„ìš”
```

**ëŒ€ì•ˆ: BART-base**
```
ì¥ì :
  âœ… í…ìŠ¤íŠ¸ ìƒì„± ê°•ì 
  âœ… 140M íŒŒë¼ë¯¸í„°
  
ë‹¨ì :
  âš ï¸ T5ë³´ë‹¤ ì‘ì€ ì»¤ë®¤ë‹ˆí‹°
```

#### **í•™ìŠµ ê³„íš**

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
```python
learning_rate = 5e-5
batch_size = 4
epochs = 3-5
max_length = 512
warmup_steps = 500
```

**ì˜ˆìƒ í•™ìŠµ ì‹œê°„**:
- Tesla T4 GPU: 2-3ì‹œê°„
- CPU: 10-15ì‹œê°„ (ë¹„ì¶”ì²œ)

**í•™ìŠµ ì½”ë“œ ìŠ¤ì¼ˆë ˆí†¤**:
```python
from transformers import T5ForConditionalGeneration, T5Tokenizer

# ëª¨ë¸ ë¡œë“œ
model = T5ForConditionalGeneration.from_pretrained('t5-base')
tokenizer = T5Tokenizer.from_pretrained('t5-base')

# ë°ì´í„° ë¡œë“œ
train_data = load_json('train_data.json')

# í•™ìŠµ
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)
trainer.train()
```

### ğŸ“Š Phase 3: ì„±ëŠ¥ í‰ê°€ (11/11 - 12/03)

#### **í‰ê°€ ì§€í‘œ**

**1. BLEU Score (ì •ëŸ‰)**
```python
from nltk.translate.bleu_score import sentence_bleu

# BLEU-1, BLEU-2, BLEU-3, BLEU-4
scores = calculate_bleu_variants(reference, candidate)
```

**ëª©í‘œ**:
- BLEU-1: >0.40
- BLEU-2: >0.30
- BLEU-4: >0.20

**2. ì •ì„± í‰ê°€**
- ì¸ë¬¼ ì¶”ì¶œ ì •í™•ë„
- ì¥ì†Œ ì¶”ì¶œ ì •í™•ë„
- ëŒ€ì‚¬ ì ì ˆì„±
- ì „ì²´ ì¼ê´€ì„±

#### **ë¹„êµ ì‹¤í—˜**

| ëª¨ë¸ | BLEU-4 (ì˜ˆìƒ) | í•™ìŠµ ì‹œê°„ |
|------|---------------|-----------|
| Baseline (Rule-based) | 0.15 | - |
| GPT-2 | 0.18 | 1ì‹œê°„ |
| T5-base | 0.25 | 3ì‹œê°„ |
| T5-large (ëª©í‘œ) | 0.30 | 8ì‹œê°„ |

### ğŸš€ í™•ì¥ ê³„íš

#### **ë‹¨ê¸° (1-2ê°œì›”)**
1. âœ… ë” ë§ì€ ë„ì„œ ì²˜ë¦¬ (50ê¶Œ â†’ 100ê¶Œ)
2. âœ… ë” í° ëª¨ë¸ ì‹¤í—˜ (T5-large, LLaMA-2)
3. âœ… í•œêµ­ì–´ ë„ì„œ ì§€ì›

#### **ì¤‘ê¸° (3-6ê°œì›”)**
1. ğŸ¯ ì‹¤ì œ ìŠ¤í¬ë¦½íŠ¸ í¬ë§· ìƒì„±
   ```
   INT. LONGBOURN - MORNING
   
   ELIZABETH walks into the drawing room.
   
   ELIZABETH
   Mr. Darcy, how do you do?
   ```

2. ğŸ¯ ì¥ë©´ ì „í™˜ ê°ì§€
3. ğŸ¯ ê°ì •/í†¤ ë¶„ì„

#### **ì¥ê¸° (6ê°œì›”+)**
1. ğŸŒŸ ìƒì—…ì  ì‘ìš©
   - ì¶œíŒì‚¬ íŒŒíŠ¸ë„ˆì‹­
   - ì˜ìƒ ì œì‘ì‚¬ í˜‘ë ¥

2. ğŸŒŸ ë‹¤êµ­ì–´ ì§€ì›
   - í•œêµ­ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´

3. ğŸŒŸ ì‹¤ì‹œê°„ ë³€í™˜ ì„œë¹„ìŠ¤
   - Web API
   - Mobile App

---

## 8. ê²°ë¡ 

### ğŸ’ª ìš°ë¦¬ì˜ ê°•ì 

1. **ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸**
   - ìˆ˜ë™ ì‘ì—… ìµœì†Œí™”
   - ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼

2. **ë†’ì€ í’ˆì§ˆ**
   - 89% ì „ì²´ í’ˆì§ˆ ì ìˆ˜
   - ì²´ê³„ì ì¸ ê²€ì¦

3. **í™•ì¥ ê°€ëŠ¥ì„±**
   - ëª¨ë“ˆí™” ì„¤ê³„
   - ë‹¤ì–‘í•œ ë„ë©”ì¸ ì ìš© ê°€ëŠ¥

### ğŸ¯ ê¸°ëŒ€ íš¨ê³¼

**í•™ìˆ ì  ê¸°ì—¬**:
- NLP ì „ì²˜ë¦¬ ë°©ë²•ë¡  ê°œì„ 
- ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ ì œê³µ

**ì‚°ì—…ì  ê°€ì¹˜**:
- ì½˜í…ì¸  ì œì‘ íš¨ìœ¨í™”
- ìƒˆë¡œìš´ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸

### ğŸ™ ê°ì‚¬í•©ë‹ˆë‹¤!

**ì§ˆë¬¸ í™˜ì˜í•©ë‹ˆë‹¤!**

---

## ë¶€ë¡: ë¼ì´ë¸Œ ë°ëª¨

### ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```python
# 1. ë„ì„œ ë‹¤ìš´ë¡œë“œ
book_text = collector.download_book(1342)
print(f"Downloaded: {len(book_text)} chars")

# 2. ì „ì²˜ë¦¬
cleaned = preprocessor.clean_text(book_text)
chapters = preprocessor.split_into_chapters(cleaned)
print(f"Found {len(chapters)} chapters")

# 3. ê°œì²´ëª… ì¶”ì¶œ
entities = extractor.extract_entities(chapters[0]['content'])
print(f"Characters: {entities['PERSON'][:3]}")

# 4. ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
scene = formatter.create_scene_structure(chapters[0]['content'], entities)
print(json.dumps(scene, indent=2)[:200])
```

**ì˜ˆìƒ ì¶œë ¥**:
```
Downloaded: 717543 chars
Found 61 chapters
Characters: [('Elizabeth', 15), ('Darcy', 12), ('Mr. Bennet', 8)]
{
  "scene_title": "CHAPTER I",
  "characters": ["Elizabeth", "Darcy"],
  "locations": ["Netherfield"],
  ...
```

---

## ì°¸ê³  ìë£Œ

### ğŸ“š ë…¼ë¬¸ ë° ë¬¸ì„œ

1. **Attention Is All You Need** (Vaswani et al., 2017)
   - Transformer ì•„í‚¤í…ì²˜

2. **Exploring the Limits of Transfer Learning with T5** (Raffel et al., 2020)
   - T5 ëª¨ë¸

3. **SpaCy: Industrial-strength NLP** (Honnibal & Montani, 2017)
   - NER ë„êµ¬

### ğŸ”— ìœ ìš©í•œ ë§í¬

- Project Gutenberg: https://www.gutenberg.org/
- Hugging Face: https://huggingface.co/
- SpaCy: https://spacy.io/
- í”„ë¡œì íŠ¸ GitHub: [ë§í¬]

---

**ë°œí‘œ ìë£Œ ë²„ì „**: 1.0  
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025ë…„ 10ì›” 14ì¼

**ì—°ë½ì²˜**: AI Lab Team  
**ì´ë©”ì¼**: [ì´ë©”ì¼ ì£¼ì†Œ]
