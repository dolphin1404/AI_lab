# 주간 타임라인 및 작업 분배

## 📅 Week 1: 데이터 전처리 (10월 12일 ~ 10월 18일)

### 🎯 목표: 50권 도서 수집 및 전처리 완료

---

## Day-by-Day 계획

### 📌 월요일 (10월 12일) - 환경 설정 및 시작

#### 오전 (09:00 - 12:00)
**전체 팀원**
- [ ] 개발 환경 설정
- [ ] 라이브러리 설치 (`pip install torch transformers datasets nltk spacy...`)
- [ ] SpaCy 모델 다운로드
- [ ] `data_preprocessing.ipynb` 실행 확인

#### 오후 (13:00 - 18:00)
**데이터 수집 담당 (1명)**
- [ ] Project Gutenberg 접근 테스트
- [ ] 도서 10권 다운로드 시작
- [ ] 원본 데이터 저장 (`raw_data/` 폴더)

**프레임워크 담당 (나머지)**
- [ ] 샘플 도서로 파이프라인 테스트
- [ ] 전처리 코드 검토 및 이해
- [ ] 에러 핸들링 추가

#### 저녁 (18:00 - 19:00)
**전체 팀원**
- [ ] 일일 회의: 진행 상황 공유
- [ ] 문제점 논의 및 해결책 모색

---

### 📌 화요일 (10월 13일) - 데이터 수집 가속

#### 오전 (09:00 - 12:00)
**데이터 수집 담당**
- [ ] 도서 15권 추가 다운로드 (누적: 25권)
- [ ] 장르 다양화 시작 (소설, 드라마, 미스터리)
- [ ] 다운로드 로그 작성

**프레임워크 담당**
- [ ] 전처리 파이프라인 최적화
- [ ] 병렬 처리 구현 검토
- [ ] 메모리 관리 개선

#### 오후 (13:00 - 18:00)
**데이터 수집 담당**
- [ ] 계속 다운로드
- [ ] 실패한 도서 재시도

**프레임워크 담당**
- [ ] 수집된 도서 전처리 시작
- [ ] 결과 검증
- [ ] 이슈 리스트 작성

#### 저녁 (19:00 - 20:00)
**전체 팀원**
- [ ] 정기 회의 (화요일 정례)
- [ ] 주간 중간 점검
- [ ] 역할 재조정 (필요시)

---

### 📌 수요일 (10월 14일) - 대규모 처리

#### 오전 (09:00 - 12:00)
**데이터 수집 담당**
- [ ] 도서 15권 추가 (누적: 40권)
- [ ] 국내 디지털 도서관 접근 연구 시작

**프레임워크 담당**
- [ ] 25권 이상 전처리 완료
- [ ] 데이터 통계 분석 시작
- [ ] 결측치 확인

#### 오후 (13:00 - 18:00)
**데이터 수집 담당**
- [ ] 목표 50권 달성
- [ ] 백업 도서 추가 다운로드 (10권)

**프레임워크 담당**
- [ ] 전체 전처리 실행
- [ ] 품질 검증 시작
- [ ] 이상치 탐지

---

### 📌 목요일 (10월 15일) - 품질 검증

#### 오전 (09:00 - 12:00)
**전체 팀원 협업**
- [ ] 전체 데이터 통계 분석
- [ ] 결측치/이상치 목록화
- [ ] 문제 도서 재처리

#### 오후 (13:00 - 18:00)
**전체 팀원 협업**
- [ ] 샘플 데이터 수동 검증
- [ ] 챕터 분할 정확도 확인
- [ ] 개체명 추출 품질 확인

#### 저녁 (19:00 - 20:00)
**전체 팀원**
- [ ] 정기 회의 (목요일 정례)
- [ ] 품질 검증 결과 공유
- [ ] 개선 사항 논의

---

### 📌 금요일 (10월 16일) - 학습 데이터 구축

#### 오전 (09:00 - 12:00)
**전체 팀원**
- [ ] 학습 데이터 포맷 정의
- [ ] 입력-출력 쌍 생성 코드 작성
- [ ] 샘플 데이터 검증

#### 오후 (13:00 - 18:00)
**전체 팀원**
- [ ] 전체 데이터셋 변환
- [ ] Train/Val/Test 분할 (80/10/10)
- [ ] JSON 파일로 저장
- [ ] 데이터셋 통계 확인

---

### 📌 주말 (10월 17-18일) - 문서화 및 정리

#### 토요일 (10월 17일)
**자율 작업**
- [ ] 진행 상황 보고서 작성
- [ ] 데이터 시각화 (통계 그래프)
- [ ] 발견된 문제 및 해결책 정리
- [ ] 코드 정리 및 주석 추가

#### 일요일 (10월 18일)
**자율 작업**
- [ ] 최종 점검
- [ ] 다음 주 계획 수립 (모델링)
- [ ] 발표 자료 초안 작성
- [ ] 휴식 및 충전 😊

---

## 📊 역할별 작업 비중

### 데이터 수집 담당 (1명)
```
월: ████████░░ 80% - 환경 설정 + 초기 수집
화: ██████████ 100% - 집중 수집
수: ██████████ 100% - 목표 달성
목: ████░░░░░░ 40% - 품질 검증 참여
금: ████░░░░░░ 40% - 데이터셋 구축 참여
```

### 프레임워크 담당 (나머지)
```
월: ████████░░ 80% - 환경 설정 + 파이프라인 테스트
화: ██████████ 100% - 전처리 시작
수: ██████████ 100% - 대규모 처리
목: ██████████ 100% - 품질 검증
금: ██████████ 100% - 데이터셋 구축
```

---

## 📈 진행 상황 추적

### 체크포인트

#### Checkpoint 1: 화요일 저녁
- [ ] 최소 25권 수집 완료
- [ ] 10권 이상 전처리 완료
- [ ] 파이프라인 안정화

#### Checkpoint 2: 목요일 저녁
- [ ] 50권 이상 수집 완료
- [ ] 전체 전처리 완료
- [ ] 품질 검증 50% 이상

#### Checkpoint 3: 금요일 저녁
- [ ] 학습 데이터셋 구축 완료
- [ ] Train/Val/Test 분할 완료
- [ ] 최종 보고서 70% 작성

---

## 🎯 일일 목표 트래커

### 사용법
매일 저녁 6시, 아래 형식으로 진행 상황 공유:

```
날짜: 2025-10-XX
담당: [이름]

완료:
- [x] 작업 1
- [x] 작업 2

진행중:
- [ ] 작업 3 (50%)

문제:
- 문제점 및 해결 방법

다음:
- 내일 할 일
```

---

## 📞 커뮤니케이션 일정

### 정기 회의
- **화요일 19:00**: 주간 중간 점검
- **목요일 19:00**: 주간 최종 점검

### 일일 체크인
- **매일 18:00**: 진행 상황 공유 (텍스트)

### 긴급 연락
- 문제 발생 즉시 팀 채팅방에 공유
- 30분 내 해결 안 되면 팀 미팅

---

## 🔄 주간 2차 (10월 19일 ~ 10월 27일) 예상 작업

### 추가 데이터 수집 (필요시)
- [ ] 100권으로 확장 (여유 있을 경우)
- [ ] 한국어 도서 추가 (국내 소스 발견 시)

### 데이터 정제 고도화
- [ ] 챕터 분할 알고리즘 개선
- [ ] 개체명 추출 정확도 향상
- [ ] 대화문/서술 분리 개선

### 모델링 준비
- [ ] 모델 최종 선정 (T5/BART/GPT-2)
- [ ] 학습 환경 구축
- [ ] 베이스라인 실험

---

## ✅ 완료 기준

### Week 1 (10월 18일까지)
- [x] ✅ 50권 이상 수집
- [x] ✅ 전체 전처리 완료
- [x] ✅ 학습 데이터셋 구축
- [x] ✅ 품질 검증 완료

### Week 2 (10월 27일까지)
- [ ] 데이터 정제 고도화
- [ ] 모델링 준비 완료
- [ ] 최종 보고서 제출

---

**현재 위치**: Week 1, Day 1 (월요일)
**다음 마일스톤**: 화요일 저녁 Checkpoint 1
**최종 마감**: 10월 27일

💪 **화이팅!** Let's start with `data_preprocessing.ipynb`!
