"""
ëª¨ë“  ì±•í„°ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ë°ì´í„° ì¬ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ë¬¸ì œ: processed_dataì˜ JSON íŒŒì¼ë“¤ì´ ì²˜ìŒ 5ê°œ ì±•í„°ë§Œ ì €ì¥ë¨
í•´ê²°: ì „ì²´ ì±•í„°ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •í•˜ì—¬ ì¬ì‹¤í–‰
"""

import json
import os
from pathlib import Path

# ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©ëœ book_ids
book_ids_to_process = [1342, 11, 98, 74, 345, 46, 1952, 1661, 2701, 84]

print("="*70)
print("ğŸ“– ì „ì²´ ì±•í„° ì¬ì²˜ë¦¬ ì‹œì‘")
print("="*70)

# processed_data í´ë” í™•ì¸
processed_dir = Path("./processed_data")
if not processed_dir.exists():
    print("âš ï¸ processed_data í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# í˜„ì¬ ìƒíƒœ í™•ì¸
print("\ní˜„ì¬ ìƒíƒœ:")
for book_id in book_ids_to_process:
    json_file = processed_dir / f"book_{book_id}.json"
    if json_file.exists():
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            total_chapters = data.get('total_chapters', 0)
            processed_chapters = len(data.get('processed_chapters', []))
            print(f"  Book {book_id}: {processed_chapters}/{total_chapters} ì±•í„° ì²˜ë¦¬ë¨")
    else:
        print(f"  Book {book_id}: íŒŒì¼ ì—†ìŒ")

print("\n"+"="*70)
print("ğŸ’¡ í•´ê²° ë°©ë²•:")
print("="*70)
print("""
ë…¸íŠ¸ë¶ì˜ BookToScriptPipeline í´ë˜ìŠ¤ì—ì„œ chaptersë¥¼ 5ê°œë¡œ ì œí•œí•˜ëŠ” ì½”ë“œê°€ ìˆìŠµë‹ˆë‹¤.

ìˆ˜ì •ì´ í•„ìš”í•œ ìœ„ì¹˜ë¥¼ ì°¾ê¸° ìœ„í•´ ë…¸íŠ¸ë¶ì„ ì§ì ‘ í¸ì§‘í•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ ë‹¨ê³„:
1. data_preprocessing.ipynb ì—´ê¸°
2. BookToScriptPipeline í´ë˜ìŠ¤ì˜ process_book ë©”ì„œë“œ ì°¾ê¸°
3. "for i, chapter in enumerate(chapters[:5])" ë¶€ë¶„ì„
   "for i, chapter in enumerate(chapters)" ë¡œ ë³€ê²½
4. ë³€ê²½ëœ ì…€ ì‹¤í–‰
5. pipeline.process_multiple_books() ì¬ì‹¤í–‰

ë˜ëŠ” ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ ìˆ˜ì •ì„ ì‹œë„í•©ë‹ˆë‹¤...
""")

print("\nì§€ê¸ˆ ë…¸íŠ¸ë¶ì„ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
print("data_preprocessing.ipynbì—ì„œ BookToScriptPipeline í´ë˜ìŠ¤ë¥¼ ì°¾ì•„")
print("chapters[:5]ë¥¼ chaptersë¡œ ë³€ê²½í•˜ê³  íŒŒì´í”„ë¼ì¸ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
